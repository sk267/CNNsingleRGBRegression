{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, BatchNormalization, LeakyReLU\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"single_rgb_image_regression_V01_{}\".format(int(time.time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data_via_ImageDataGenerator():\n",
    "#     train = ImageDataGenerator(rescale=1/255)\n",
    "#     validation = ImageDataGenerator(rescale=1/255)\n",
    "#     train_dataset = train.flow_from_directory(\"../Data/Train/smallTown\",\n",
    "#                                               target_size=(60, 60), batch_size=3, class_mode='binary')\n",
    "#     validation_dataset = train.flow_from_directory(\"../Data/Train/smallTown\",\n",
    "#                                                target_size=(60, 60), batch_size=3, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_via_numpy_load():\n",
    "    return (np.load(\"CNN_trainset_single_RGB_regression_V01_X.npy\")/255, np.load(\"CNN_trainset_single_RGB_regression_V01_Y.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_data_via_numpy_load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.18431373, 0.10980392, 0.00784314],\n",
       "         [0.22745098, 0.15294118, 0.05098039],\n",
       "         [0.23921569, 0.16470588, 0.0627451 ],\n",
       "         ...,\n",
       "         [0.21176471, 0.1254902 , 0.01960784],\n",
       "         [0.22745098, 0.1372549 , 0.03529412],\n",
       "         [0.23921569, 0.15294118, 0.05098039]],\n",
       "\n",
       "        [[0.18823529, 0.11764706, 0.01568627],\n",
       "         [0.18823529, 0.11372549, 0.01568627],\n",
       "         [0.21568627, 0.14117647, 0.04313725],\n",
       "         ...,\n",
       "         [0.21960784, 0.13333333, 0.02745098],\n",
       "         [0.20392157, 0.11764706, 0.01176471],\n",
       "         [0.20392157, 0.11764706, 0.01176471]],\n",
       "\n",
       "        [[0.18823529, 0.11372549, 0.01960784],\n",
       "         [0.18039216, 0.10588235, 0.01176471],\n",
       "         [0.17647059, 0.10588235, 0.00784314],\n",
       "         ...,\n",
       "         [0.21960784, 0.13333333, 0.02352941],\n",
       "         [0.25098039, 0.16862745, 0.05882353],\n",
       "         [0.25490196, 0.16862745, 0.05882353]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.19607843, 0.11764706, 0.01568627],\n",
       "         [0.21960784, 0.14509804, 0.04313725],\n",
       "         [0.23529412, 0.15686275, 0.05490196],\n",
       "         ...,\n",
       "         [0.22745098, 0.14509804, 0.03529412],\n",
       "         [0.21568627, 0.12941176, 0.01960784],\n",
       "         [0.24705882, 0.16470588, 0.05490196]],\n",
       "\n",
       "        [[0.20784314, 0.13333333, 0.02352941],\n",
       "         [0.20784314, 0.12941176, 0.02352941],\n",
       "         [0.23137255, 0.15686275, 0.04705882],\n",
       "         ...,\n",
       "         [0.21176471, 0.12941176, 0.02352941],\n",
       "         [0.21176471, 0.12941176, 0.02352941],\n",
       "         [0.20392157, 0.12156863, 0.01568627]],\n",
       "\n",
       "        [[0.2       , 0.1254902 , 0.01960784],\n",
       "         [0.18431373, 0.10980392, 0.00392157],\n",
       "         [0.18823529, 0.11372549, 0.01176471],\n",
       "         ...,\n",
       "         [0.22352941, 0.1372549 , 0.03137255],\n",
       "         [0.24313725, 0.15686275, 0.05098039],\n",
       "         [0.2745098 , 0.18823529, 0.08235294]]],\n",
       "\n",
       "\n",
       "       [[[0.10980392, 0.06666667, 0.00784314],\n",
       "         [0.16078431, 0.11372549, 0.05882353],\n",
       "         [0.21960784, 0.17647059, 0.11764706],\n",
       "         ...,\n",
       "         [0.16862745, 0.13333333, 0.02352941],\n",
       "         [0.15686275, 0.11764706, 0.00392157],\n",
       "         [0.2745098 , 0.23137255, 0.10980392]],\n",
       "\n",
       "        [[0.05098039, 0.02745098, 0.        ],\n",
       "         [0.10980392, 0.08235294, 0.03921569],\n",
       "         [0.15686275, 0.13333333, 0.08627451],\n",
       "         ...,\n",
       "         [0.09019608, 0.03529412, 0.        ],\n",
       "         [0.09803922, 0.04313725, 0.        ],\n",
       "         [0.08627451, 0.03529412, 0.        ]],\n",
       "\n",
       "        [[0.05098039, 0.02352941, 0.        ],\n",
       "         [0.08627451, 0.05882353, 0.        ],\n",
       "         [0.07058824, 0.04313725, 0.        ],\n",
       "         ...,\n",
       "         [0.14509804, 0.08235294, 0.        ],\n",
       "         [0.3372549 , 0.26666667, 0.12156863],\n",
       "         [0.37254902, 0.29803922, 0.14509804]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21960784, 0.14117647, 0.        ],\n",
       "         [0.32941176, 0.25490196, 0.09411765],\n",
       "         [0.40784314, 0.3372549 , 0.18823529],\n",
       "         ...,\n",
       "         [0.16470588, 0.18823529, 0.07058824],\n",
       "         [0.09803922, 0.1254902 , 0.00392157],\n",
       "         [0.18823529, 0.22745098, 0.09803922]],\n",
       "\n",
       "        [[0.20392157, 0.16862745, 0.01568627],\n",
       "         [0.2       , 0.16862745, 0.02352941],\n",
       "         [0.33333333, 0.30588235, 0.16862745],\n",
       "         ...,\n",
       "         [0.0745098 , 0.0627451 , 0.        ],\n",
       "         [0.08627451, 0.0745098 , 0.        ],\n",
       "         [0.05490196, 0.05098039, 0.        ]],\n",
       "\n",
       "        [[0.08235294, 0.05490196, 0.        ],\n",
       "         [0.0745098 , 0.04705882, 0.        ],\n",
       "         [0.05490196, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.15686275, 0.17647059, 0.03137255],\n",
       "         [0.19215686, 0.20784314, 0.0627451 ],\n",
       "         [0.38431373, 0.40784314, 0.25882353]]],\n",
       "\n",
       "\n",
       "       [[[0.18823529, 0.11372549, 0.        ],\n",
       "         [0.32156863, 0.24705882, 0.10196078],\n",
       "         [0.20784314, 0.13333333, 0.        ],\n",
       "         ...,\n",
       "         [0.29803922, 0.19607843, 0.0627451 ],\n",
       "         [0.20392157, 0.10196078, 0.        ],\n",
       "         [0.28235294, 0.18039216, 0.04705882]],\n",
       "\n",
       "        [[0.22352941, 0.10980392, 0.        ],\n",
       "         [0.25490196, 0.14509804, 0.        ],\n",
       "         [0.2627451 , 0.14901961, 0.        ],\n",
       "         ...,\n",
       "         [0.42352941, 0.31764706, 0.16470588],\n",
       "         [0.2       , 0.09803922, 0.        ],\n",
       "         [0.42352941, 0.3254902 , 0.16862745]],\n",
       "\n",
       "        [[0.22745098, 0.10588235, 0.        ],\n",
       "         [0.48627451, 0.36862745, 0.21960784],\n",
       "         [0.32156863, 0.20392157, 0.05098039],\n",
       "         ...,\n",
       "         [0.26666667, 0.16470588, 0.02745098],\n",
       "         [0.21176471, 0.11372549, 0.        ],\n",
       "         [0.25882353, 0.16470588, 0.01960784]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21568627, 0.14117647, 0.        ],\n",
       "         [0.19607843, 0.12156863, 0.        ],\n",
       "         [0.23137255, 0.15686275, 0.01568627],\n",
       "         ...,\n",
       "         [0.31372549, 0.20392157, 0.06666667],\n",
       "         [0.40392157, 0.29411765, 0.15686275],\n",
       "         [0.21960784, 0.10588235, 0.        ]],\n",
       "\n",
       "        [[0.28235294, 0.19215686, 0.03921569],\n",
       "         [0.18823529, 0.09411765, 0.        ],\n",
       "         [0.34117647, 0.25098039, 0.09803922],\n",
       "         ...,\n",
       "         [0.25882353, 0.16470588, 0.02352941],\n",
       "         [0.36078431, 0.26666667, 0.12156863],\n",
       "         [0.20392157, 0.10980392, 0.        ]],\n",
       "\n",
       "        [[0.36078431, 0.27058824, 0.12941176],\n",
       "         [0.2       , 0.10588235, 0.        ],\n",
       "         [0.44313725, 0.34901961, 0.20784314],\n",
       "         ...,\n",
       "         [0.21176471, 0.11372549, 0.        ],\n",
       "         [0.20784314, 0.10980392, 0.        ],\n",
       "         [0.18823529, 0.09019608, 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.30980392, 0.17647059, 0.01960784],\n",
       "         [0.30980392, 0.17254902, 0.01960784],\n",
       "         [0.31372549, 0.17647059, 0.01960784],\n",
       "         ...,\n",
       "         [0.32941176, 0.2       , 0.04313725],\n",
       "         [0.31764706, 0.19215686, 0.03137255],\n",
       "         [0.30196078, 0.17647059, 0.01568627]],\n",
       "\n",
       "        [[0.30980392, 0.18039216, 0.01568627],\n",
       "         [0.42745098, 0.29411765, 0.12941176],\n",
       "         [0.35686275, 0.22352941, 0.05490196],\n",
       "         ...,\n",
       "         [0.33333333, 0.20392157, 0.04705882],\n",
       "         [0.32156863, 0.19607843, 0.03529412],\n",
       "         [0.30588235, 0.18039216, 0.01960784]],\n",
       "\n",
       "        [[0.30588235, 0.17254902, 0.00784314],\n",
       "         [0.4       , 0.2627451 , 0.09803922],\n",
       "         [0.35686275, 0.22352941, 0.05490196],\n",
       "         ...,\n",
       "         [0.41960784, 0.28627451, 0.11372549],\n",
       "         [0.37647059, 0.24705882, 0.0745098 ],\n",
       "         [0.30980392, 0.18039216, 0.00784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.36862745, 0.23529412, 0.07058824],\n",
       "         [0.30196078, 0.16862745, 0.00392157],\n",
       "         [0.38431373, 0.25098039, 0.08627451],\n",
       "         ...,\n",
       "         [0.30980392, 0.17647059, 0.01568627],\n",
       "         [0.37647059, 0.24313725, 0.07843137],\n",
       "         [0.38823529, 0.25490196, 0.09019608]],\n",
       "\n",
       "        [[0.29803922, 0.16862745, 0.01176471],\n",
       "         [0.31372549, 0.18431373, 0.02745098],\n",
       "         [0.30588235, 0.17647059, 0.01960784],\n",
       "         ...,\n",
       "         [0.30196078, 0.17254902, 0.01568627],\n",
       "         [0.30196078, 0.17254902, 0.01568627],\n",
       "         [0.29411765, 0.16470588, 0.01176471]],\n",
       "\n",
       "        [[0.40392157, 0.27843137, 0.10980392],\n",
       "         [0.29411765, 0.17254902, 0.00392157],\n",
       "         [0.41960784, 0.29411765, 0.1254902 ],\n",
       "         ...,\n",
       "         [0.30980392, 0.17647059, 0.00784314],\n",
       "         [0.36862745, 0.23529412, 0.06666667],\n",
       "         [0.40392157, 0.27058824, 0.09803922]]],\n",
       "\n",
       "\n",
       "       [[[0.34509804, 0.21568627, 0.03529412],\n",
       "         [0.43529412, 0.30588235, 0.1254902 ],\n",
       "         [0.39215686, 0.25882353, 0.07843137],\n",
       "         ...,\n",
       "         [0.33333333, 0.20392157, 0.02745098],\n",
       "         [0.37254902, 0.23921569, 0.0627451 ],\n",
       "         [0.40392157, 0.2745098 , 0.09803922]],\n",
       "\n",
       "        [[0.32156863, 0.19215686, 0.03137255],\n",
       "         [0.34901961, 0.21960784, 0.05882353],\n",
       "         [0.33333333, 0.20392157, 0.04313725],\n",
       "         ...,\n",
       "         [0.3254902 , 0.19607843, 0.02352941],\n",
       "         [0.36470588, 0.23529412, 0.0627451 ],\n",
       "         [0.39607843, 0.2627451 , 0.09411765]],\n",
       "\n",
       "        [[0.30196078, 0.17254902, 0.02352941],\n",
       "         [0.29019608, 0.16470588, 0.01176471],\n",
       "         [0.30588235, 0.18039216, 0.02745098],\n",
       "         ...,\n",
       "         [0.30980392, 0.18823529, 0.03529412],\n",
       "         [0.29411765, 0.16862745, 0.01568627],\n",
       "         [0.29411765, 0.16862745, 0.01568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.29803922, 0.17254902, 0.01568627],\n",
       "         [0.29411765, 0.16862745, 0.01176471],\n",
       "         [0.30980392, 0.18039216, 0.02745098],\n",
       "         ...,\n",
       "         [0.29411765, 0.16862745, 0.01960784],\n",
       "         [0.29019608, 0.16078431, 0.01568627],\n",
       "         [0.29019608, 0.16078431, 0.01568627]],\n",
       "\n",
       "        [[0.38039216, 0.24705882, 0.0745098 ],\n",
       "         [0.4       , 0.2627451 , 0.09019608],\n",
       "         [0.33333333, 0.2       , 0.02745098],\n",
       "         ...,\n",
       "         [0.32941176, 0.19607843, 0.02745098],\n",
       "         [0.38431373, 0.24705882, 0.08235294],\n",
       "         [0.37647059, 0.23921569, 0.0745098 ]],\n",
       "\n",
       "        [[0.38431373, 0.25098039, 0.07843137],\n",
       "         [0.4       , 0.26666667, 0.09411765],\n",
       "         [0.34117647, 0.20784314, 0.03529412],\n",
       "         ...,\n",
       "         [0.3372549 , 0.20392157, 0.03529412],\n",
       "         [0.38823529, 0.25882353, 0.09019608],\n",
       "         [0.37647059, 0.24313725, 0.0745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.09019608, 0.10588235, 0.05490196],\n",
       "         [0.0745098 , 0.08627451, 0.03921569],\n",
       "         [0.07843137, 0.09019608, 0.04313725],\n",
       "         ...,\n",
       "         [0.09411765, 0.05490196, 0.03137255],\n",
       "         [0.09411765, 0.05490196, 0.03137255],\n",
       "         [0.07058824, 0.02745098, 0.00784314]],\n",
       "\n",
       "        [[0.08235294, 0.09803922, 0.04705882],\n",
       "         [0.08235294, 0.09411765, 0.04705882],\n",
       "         [0.09803922, 0.10980392, 0.05882353],\n",
       "         ...,\n",
       "         [0.08627451, 0.04705882, 0.02745098],\n",
       "         [0.08627451, 0.04705882, 0.02745098],\n",
       "         [0.07058824, 0.03529412, 0.01176471]],\n",
       "\n",
       "        [[0.07058824, 0.08627451, 0.03529412],\n",
       "         [0.05882353, 0.07058824, 0.02352941],\n",
       "         [0.06666667, 0.07843137, 0.02745098],\n",
       "         ...,\n",
       "         [0.07843137, 0.04313725, 0.02352941],\n",
       "         [0.08627451, 0.05098039, 0.03137255],\n",
       "         [0.0745098 , 0.03921569, 0.01960784]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03529412, 0.02352941, 0.        ],\n",
       "         [0.03529412, 0.02352941, 0.        ],\n",
       "         [0.03921569, 0.02352941, 0.        ],\n",
       "         ...,\n",
       "         [0.04313725, 0.03529412, 0.        ],\n",
       "         [0.03529412, 0.02745098, 0.        ],\n",
       "         [0.02745098, 0.01960784, 0.        ]],\n",
       "\n",
       "        [[0.0627451 , 0.04705882, 0.        ],\n",
       "         [0.09411765, 0.0745098 , 0.01568627],\n",
       "         [0.10980392, 0.09411765, 0.03137255],\n",
       "         ...,\n",
       "         [0.01568627, 0.00784314, 0.        ],\n",
       "         [0.02352941, 0.01568627, 0.        ],\n",
       "         [0.00392157, 0.        , 0.        ]],\n",
       "\n",
       "        [[0.0745098 , 0.05098039, 0.        ],\n",
       "         [0.0745098 , 0.05098039, 0.        ],\n",
       "         [0.12156863, 0.09803922, 0.03137255],\n",
       "         ...,\n",
       "         [0.03921569, 0.03137255, 0.        ],\n",
       "         [0.05490196, 0.04705882, 0.        ],\n",
       "         [0.03137255, 0.02352941, 0.        ]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 60, 60, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 60, 60, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = X.reshape(-1, 60, 60, 3)\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Conv-Layer\n",
    "    model.add(Conv2D(128, (3, 3), input_shape=(X.shape[1:])))\n",
    "    model.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2, 2))\n",
    "\n",
    "    # 2nd Conv-Layer\n",
    "    model.add(Conv2D(192, (3, 3)))\n",
    "    model.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # 3rd Conv-Layer\n",
    "    model.add(Conv2D(320, (3, 3)))\n",
    "    model.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 4th Conv-Layer\n",
    "    model.add(Conv2D(576, (3, 3)))\n",
    "    model.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # 1st Fully-Connected\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "\n",
    "    # 2nd Fully-Connected\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "\n",
    "    # 3rd Fully-Connected\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 58, 58, 128)       3584      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 58, 58, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 29, 29, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 192)       221376    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 27, 27, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 27, 192)       768       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 320)       553280    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 320)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 320)       1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 320)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 576)         1659456   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 576)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 576)         2304      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 576)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2363392   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 21,591,361\n",
      "Trainable params: 21,588,929\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/169 [==>...........................] - ETA: 2:00 - loss: 0.1427 - accuracy: 0.3391"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Main\\MA_PROGR\\Code_CNN_singleRGB_Regression\\CNN.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Main/MA_PROGR/Code_CNN_singleRGB_Regression/CNN.ipynb#ch0000011?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, Y, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tensorboard])\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1175'>1176</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1176'>1177</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1177'>1178</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1178'>1179</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1179'>1180</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1180'>1181</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1181'>1182</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1182'>1183</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1183'>1184</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1184'>1185</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=885'>886</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=888'>889</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=890'>891</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=891'>892</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=915'>916</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=918'>919</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=919'>920</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/def_function.py?line=920'>921</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=3019'>3020</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=3020'>3021</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=3021'>3022</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=3022'>3023</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=3023'>3024</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1955'>1956</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1956'>1957</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1957'>1958</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Programme\\Anaconda3\\envs\\tf_training\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///d%3A/Programme/Anaconda3/envs/tf_training/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=32, epochs=1, validation_split=0.1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"./models/single_rgb_image_big_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alias\n",
    "\n",
    "# img1 = Image.open(\n",
    "#     \"D:\\Main\\MA_PROGR\\Data\\Train\\LED_Wand_Aufnahmen\\Alias\\LED_Wand_20001.png\")\n",
    "# img1 = np.asarray(img1)/255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img1 = img1.reshape(1,60,60,3)\n",
    "# print(img1.shape)\n",
    "# # print(img1)\n",
    "# res1 = model.predict(img1)\n",
    "# print(res1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NoAlias\n",
    "\n",
    "# img2 = Image.open(\n",
    "#     \"D:\\\\Main\\\\MA_PROGR\\\\Data\\\\Train\\\\LED_Wand_Aufnahmen\\\\NoAlias\\\\abstract_cross_203.png\")\n",
    "# img2 = np.asarray(img2)/255\n",
    "\n",
    "# img2 = img2.reshape(1, 60, 60, 3)\n",
    "# img2.shape\n",
    "# # print(img2)\n",
    "# res2 = model.predict(img2)\n",
    "# print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(img2.reshape(60, 60, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/single_rgb_image_trainset_V04_1653260543\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/single_rgb_image_trainset_V04_1653260543\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, \"./models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbe6f1f0ffae94815f8b68c5970304948992b116503ec65631f55d524065bfaa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_training')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
